{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1393cc5",
   "metadata": {},
   "source": [
    "# ü§ñ Model Training for Traffic Flow Optimization\n",
    "\n",
    "**Phase 3: Modeling, Analysis, and Evaluation**\n",
    "\n",
    "## Overview\n",
    "This notebook trains multiple models for traffic congestion prediction:\n",
    "- **LSTM**: Long Short-Term Memory for sequential patterns\n",
    "- **XGBoost**: Gradient boosting for tabular features\n",
    "- **ARIMA**: Time-series baseline\n",
    "- **Random Forest**: Ensemble tree model\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Data Science Team  \n",
    "**Date:** November 2025  \n",
    "**Project:** Bangkok Traffic Flow Optimization (CPE312 Capstone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f037c9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model_utils:Random seeds set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n",
      "NumPy: 2.3.4\n",
      "Pandas: 2.3.3\n",
      "XGBoost: 3.1.2\n"
     ]
    }
   ],
   "source": [
    "# Setup and Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import ML libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Import custom scripts\n",
    "import sys\n",
    "sys.path.insert(0, '../05_Scripts/')\n",
    "from modeling import (\n",
    "    create_sequences,\n",
    "    temporal_train_test_split,\n",
    "    train_xgboost_model,\n",
    "    train_random_forest_model,\n",
    "    train_arima_model\n",
    ")\n",
    "from model_utils import save_model, set_random_seeds\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "set_random_seeds(42)\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"XGBoost: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d64e51",
   "metadata": {},
   "source": [
    "## 1. Load Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e53f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1652, 37)\n",
      "\n",
      "Target: congestion_index\n",
      "Features: 33 numeric columns\n",
      "Sample features: ['traffic_volume', 'average_speed', 'year', 'month', 'day']...\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "DATA_PATH = Path('../02_Data/Processed/')\n",
    "MODEL_PATH = Path('../02_Model_Development/Trained_Models/')\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load engineered features (from Notebook 04)\n",
    "df = pd.read_csv(DATA_PATH / 'features_engineered.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Define target\n",
    "target_col = 'congestion_index'\n",
    "\n",
    "# Select only numeric columns for features (exclude date and target)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_cols = [col for col in numeric_cols if col != target_col]\n",
    "\n",
    "# Handle any remaining NaN values\n",
    "df[feature_cols] = df[feature_cols].fillna(0)\n",
    "\n",
    "print(f\"\\nTarget: {target_col}\")\n",
    "print(f\"Features: {len(feature_cols)} numeric columns\")\n",
    "print(f\"Sample features: {feature_cols[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba3ac1",
   "metadata": {},
   "source": [
    "## 2. Prepare Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab4b86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling:Split sizes - Train: 991, Val: 330, Test: 331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (991, 33)\n",
      "Validation set: (330, 33)\n",
      "Test set: (331, 33)\n"
     ]
    }
   ],
   "source": [
    "# Temporal train/val/test split (60/20/20)\n",
    "train_df, val_df, test_df = temporal_train_test_split(\n",
    "    df, \n",
    "    date_col='date' if 'date' in df.columns else df.columns[0],\n",
    "    train_ratio=0.6,\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.2\n",
    ")\n",
    "\n",
    "# Extract features and targets\n",
    "X_train = train_df[feature_cols].values\n",
    "y_train = train_df[target_col].values\n",
    "\n",
    "X_val = val_df[feature_cols].values\n",
    "y_val = val_df[target_col].values\n",
    "\n",
    "X_test = test_df[feature_cols].values\n",
    "y_test = test_df[target_col].values\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c1cc29",
   "metadata": {},
   "source": [
    "## 3. Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8040b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling:Starting XGBoost training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "[0]\tvalidation_0-rmse:7.90538\n",
      "[1]\tvalidation_0-rmse:7.46043\n",
      "[2]\tvalidation_0-rmse:7.12928\n",
      "[3]\tvalidation_0-rmse:6.76722\n",
      "[4]\tvalidation_0-rmse:6.48022\n",
      "[5]\tvalidation_0-rmse:6.23008\n",
      "[0]\tvalidation_0-rmse:7.90538\n",
      "[1]\tvalidation_0-rmse:7.46043\n",
      "[2]\tvalidation_0-rmse:7.12928\n",
      "[3]\tvalidation_0-rmse:6.76722\n",
      "[4]\tvalidation_0-rmse:6.48022\n",
      "[5]\tvalidation_0-rmse:6.23008\n",
      "[6]\tvalidation_0-rmse:6.03583\n",
      "[7]\tvalidation_0-rmse:5.87765\n",
      "[8]\tvalidation_0-rmse:5.74751\n",
      "[9]\tvalidation_0-rmse:5.65878\n",
      "[10]\tvalidation_0-rmse:5.56027\n",
      "[11]\tvalidation_0-rmse:5.45645\n",
      "[6]\tvalidation_0-rmse:6.03583\n",
      "[7]\tvalidation_0-rmse:5.87765\n",
      "[8]\tvalidation_0-rmse:5.74751\n",
      "[9]\tvalidation_0-rmse:5.65878\n",
      "[10]\tvalidation_0-rmse:5.56027\n",
      "[11]\tvalidation_0-rmse:5.45645\n",
      "[12]\tvalidation_0-rmse:5.38381\n",
      "[13]\tvalidation_0-rmse:5.33062\n",
      "[14]\tvalidation_0-rmse:5.30465\n",
      "[15]\tvalidation_0-rmse:5.24887\n",
      "[16]\tvalidation_0-rmse:5.22018\n",
      "[17]\tvalidation_0-rmse:5.19039\n",
      "[12]\tvalidation_0-rmse:5.38381\n",
      "[13]\tvalidation_0-rmse:5.33062\n",
      "[14]\tvalidation_0-rmse:5.30465\n",
      "[15]\tvalidation_0-rmse:5.24887\n",
      "[16]\tvalidation_0-rmse:5.22018\n",
      "[17]\tvalidation_0-rmse:5.19039\n",
      "[18]\tvalidation_0-rmse:5.16029\n",
      "[19]\tvalidation_0-rmse:5.15558\n",
      "[20]\tvalidation_0-rmse:5.14028\n",
      "[21]\tvalidation_0-rmse:5.13365\n",
      "[22]\tvalidation_0-rmse:5.11724\n",
      "[23]\tvalidation_0-rmse:5.10325\n",
      "[18]\tvalidation_0-rmse:5.16029\n",
      "[19]\tvalidation_0-rmse:5.15558\n",
      "[20]\tvalidation_0-rmse:5.14028\n",
      "[21]\tvalidation_0-rmse:5.13365\n",
      "[22]\tvalidation_0-rmse:5.11724\n",
      "[23]\tvalidation_0-rmse:5.10325\n",
      "[24]\tvalidation_0-rmse:5.07609\n",
      "[25]\tvalidation_0-rmse:5.05990\n",
      "[26]\tvalidation_0-rmse:5.04227\n",
      "[27]\tvalidation_0-rmse:5.05340\n",
      "[28]\tvalidation_0-rmse:5.06171\n",
      "[29]\tvalidation_0-rmse:5.05893\n",
      "[24]\tvalidation_0-rmse:5.07609\n",
      "[25]\tvalidation_0-rmse:5.05990\n",
      "[26]\tvalidation_0-rmse:5.04227\n",
      "[27]\tvalidation_0-rmse:5.05340\n",
      "[28]\tvalidation_0-rmse:5.06171\n",
      "[29]\tvalidation_0-rmse:5.05893\n",
      "[30]\tvalidation_0-rmse:5.05343\n",
      "[31]\tvalidation_0-rmse:5.05740\n",
      "[32]\tvalidation_0-rmse:5.05485\n",
      "[33]\tvalidation_0-rmse:5.04773\n",
      "[34]\tvalidation_0-rmse:5.03657\n",
      "[35]\tvalidation_0-rmse:5.03094\n",
      "[30]\tvalidation_0-rmse:5.05343\n",
      "[31]\tvalidation_0-rmse:5.05740\n",
      "[32]\tvalidation_0-rmse:5.05485\n",
      "[33]\tvalidation_0-rmse:5.04773\n",
      "[34]\tvalidation_0-rmse:5.03657\n",
      "[35]\tvalidation_0-rmse:5.03094\n",
      "[36]\tvalidation_0-rmse:5.04083\n",
      "[37]\tvalidation_0-rmse:5.03462\n",
      "[38]\tvalidation_0-rmse:5.03916\n",
      "[39]\tvalidation_0-rmse:5.04615\n",
      "[40]\tvalidation_0-rmse:5.04468\n",
      "[36]\tvalidation_0-rmse:5.04083\n",
      "[37]\tvalidation_0-rmse:5.03462\n",
      "[38]\tvalidation_0-rmse:5.03916\n",
      "[39]\tvalidation_0-rmse:5.04615\n",
      "[40]\tvalidation_0-rmse:5.04468\n",
      "[41]\tvalidation_0-rmse:5.04806\n",
      "[42]\tvalidation_0-rmse:5.04485\n",
      "[43]\tvalidation_0-rmse:5.03009\n",
      "[44]\tvalidation_0-rmse:5.03175\n",
      "[45]\tvalidation_0-rmse:5.04378\n",
      "[46]\tvalidation_0-rmse:5.04964\n",
      "[41]\tvalidation_0-rmse:5.04806\n",
      "[42]\tvalidation_0-rmse:5.04485\n",
      "[43]\tvalidation_0-rmse:5.03009\n",
      "[44]\tvalidation_0-rmse:5.03175\n",
      "[45]\tvalidation_0-rmse:5.04378\n",
      "[46]\tvalidation_0-rmse:5.04964\n",
      "[47]\tvalidation_0-rmse:5.05341\n",
      "[48]\tvalidation_0-rmse:5.04739\n",
      "[49]\tvalidation_0-rmse:5.04956\n",
      "[50]\tvalidation_0-rmse:5.05906\n",
      "[51]\tvalidation_0-rmse:5.06014\n",
      "[52]\tvalidation_0-rmse:5.06516\n",
      "[47]\tvalidation_0-rmse:5.05341\n",
      "[48]\tvalidation_0-rmse:5.04739\n",
      "[49]\tvalidation_0-rmse:5.04956\n",
      "[50]\tvalidation_0-rmse:5.05906\n",
      "[51]\tvalidation_0-rmse:5.06014\n",
      "[52]\tvalidation_0-rmse:5.06516\n",
      "[53]\tvalidation_0-rmse:5.06532\n",
      "[54]\tvalidation_0-rmse:5.07489\n",
      "[55]\tvalidation_0-rmse:5.07919\n",
      "[56]\tvalidation_0-rmse:5.08337\n",
      "[57]\tvalidation_0-rmse:5.07252\n",
      "[58]\tvalidation_0-rmse:5.07358\n",
      "[53]\tvalidation_0-rmse:5.06532\n",
      "[54]\tvalidation_0-rmse:5.07489\n",
      "[55]\tvalidation_0-rmse:5.07919\n",
      "[56]\tvalidation_0-rmse:5.08337\n",
      "[57]\tvalidation_0-rmse:5.07252\n",
      "[58]\tvalidation_0-rmse:5.07358\n",
      "[59]\tvalidation_0-rmse:5.07815\n",
      "[60]\tvalidation_0-rmse:5.07578\n",
      "[61]\tvalidation_0-rmse:5.07922\n",
      "[62]\tvalidation_0-rmse:5.07814\n",
      "[63]\tvalidation_0-rmse:5.08225\n",
      "[64]\tvalidation_0-rmse:5.08190\n",
      "[59]\tvalidation_0-rmse:5.07815\n",
      "[60]\tvalidation_0-rmse:5.07578\n",
      "[61]\tvalidation_0-rmse:5.07922\n",
      "[62]\tvalidation_0-rmse:5.07814\n",
      "[63]\tvalidation_0-rmse:5.08225\n",
      "[64]\tvalidation_0-rmse:5.08190\n",
      "[65]\tvalidation_0-rmse:5.07649\n",
      "[66]\tvalidation_0-rmse:5.08114\n",
      "[67]\tvalidation_0-rmse:5.08037\n",
      "[68]\tvalidation_0-rmse:5.08096\n",
      "[69]\tvalidation_0-rmse:5.08290\n",
      "[70]\tvalidation_0-rmse:5.07930\n",
      "[71]\tvalidation_0-rmse:5.07629\n",
      "[65]\tvalidation_0-rmse:5.07649\n",
      "[66]\tvalidation_0-rmse:5.08114\n",
      "[67]\tvalidation_0-rmse:5.08037\n",
      "[68]\tvalidation_0-rmse:5.08096\n",
      "[69]\tvalidation_0-rmse:5.08290\n",
      "[70]\tvalidation_0-rmse:5.07930\n",
      "[71]\tvalidation_0-rmse:5.07629\n",
      "[72]\tvalidation_0-rmse:5.07916\n",
      "[73]\tvalidation_0-rmse:5.07896\n",
      "[74]\tvalidation_0-rmse:5.07408\n",
      "[75]\tvalidation_0-rmse:5.07460\n",
      "[76]\tvalidation_0-rmse:5.07108\n",
      "[77]\tvalidation_0-rmse:5.07075\n",
      "[72]\tvalidation_0-rmse:5.07916\n",
      "[73]\tvalidation_0-rmse:5.07896\n",
      "[74]\tvalidation_0-rmse:5.07408\n",
      "[75]\tvalidation_0-rmse:5.07460\n",
      "[76]\tvalidation_0-rmse:5.07108\n",
      "[77]\tvalidation_0-rmse:5.07075\n",
      "[78]\tvalidation_0-rmse:5.06686\n",
      "[79]\tvalidation_0-rmse:5.06497\n",
      "[80]\tvalidation_0-rmse:5.06521\n",
      "[81]\tvalidation_0-rmse:5.06961\n",
      "[82]\tvalidation_0-rmse:5.06827\n",
      "[83]\tvalidation_0-rmse:5.07364\n",
      "[84]\tvalidation_0-rmse:5.07733\n",
      "[78]\tvalidation_0-rmse:5.06686\n",
      "[79]\tvalidation_0-rmse:5.06497\n",
      "[80]\tvalidation_0-rmse:5.06521\n",
      "[81]\tvalidation_0-rmse:5.06961\n",
      "[82]\tvalidation_0-rmse:5.06827\n",
      "[83]\tvalidation_0-rmse:5.07364\n",
      "[84]\tvalidation_0-rmse:5.07733\n",
      "[85]\tvalidation_0-rmse:5.08577\n",
      "[86]\tvalidation_0-rmse:5.08738\n",
      "[87]\tvalidation_0-rmse:5.08747\n",
      "[88]\tvalidation_0-rmse:5.08908\n",
      "[89]\tvalidation_0-rmse:5.08997\n",
      "[90]\tvalidation_0-rmse:5.08798\n",
      "[85]\tvalidation_0-rmse:5.08577\n",
      "[86]\tvalidation_0-rmse:5.08738\n",
      "[87]\tvalidation_0-rmse:5.08747\n",
      "[88]\tvalidation_0-rmse:5.08908\n",
      "[89]\tvalidation_0-rmse:5.08997\n",
      "[90]\tvalidation_0-rmse:5.08798\n",
      "[91]\tvalidation_0-rmse:5.08762\n",
      "[92]\tvalidation_0-rmse:5.08772\n",
      "[93]\tvalidation_0-rmse:5.09481\n",
      "[94]\tvalidation_0-rmse:5.09477\n",
      "[95]\tvalidation_0-rmse:5.09287\n",
      "[96]\tvalidation_0-rmse:5.09278\n",
      "[91]\tvalidation_0-rmse:5.08762\n",
      "[92]\tvalidation_0-rmse:5.08772\n",
      "[93]\tvalidation_0-rmse:5.09481\n",
      "[94]\tvalidation_0-rmse:5.09477\n",
      "[95]\tvalidation_0-rmse:5.09287\n",
      "[96]\tvalidation_0-rmse:5.09278\n",
      "[97]\tvalidation_0-rmse:5.09181\n",
      "[98]\tvalidation_0-rmse:5.09424\n",
      "[99]\tvalidation_0-rmse:5.09753\n",
      "[97]\tvalidation_0-rmse:5.09181\n",
      "[98]\tvalidation_0-rmse:5.09424\n",
      "[99]\tvalidation_0-rmse:5.09753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling:Model saved to ../02_Model_Development/Trained_Models/xgboost_model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ XGBoost training complete!\n"
     ]
    }
   ],
   "source": [
    "# XGBoost configuration\n",
    "xgb_config = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Train XGBoost\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model, xgb_info = train_xgboost_model(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    config=xgb_config,\n",
    "    save_path=str(MODEL_PATH / 'xgboost_model.pkl')\n",
    ")\n",
    "\n",
    "print(\"‚úÖ XGBoost training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482b6360",
   "metadata": {},
   "source": [
    "## 4. Train Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "053defeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling:Starting Random Forest training...\n",
      "INFO:modeling:Model saved to ../02_Model_Development/Trained_Models/random_forest_model.pkl\n",
      "INFO:modeling:Model saved to ../02_Model_Development/Trained_Models/random_forest_model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "‚úÖ Random Forest training complete!\n"
     ]
    }
   ],
   "source": [
    "# Random Forest configuration\n",
    "rf_config = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 15,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Train Random Forest\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model, rf_info = train_random_forest_model(\n",
    "    X_train, y_train,\n",
    "    config=rf_config,\n",
    "    save_path=str(MODEL_PATH / 'random_forest_model.pkl')\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Random Forest training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a155fcc0",
   "metadata": {},
   "source": [
    "## 5. Train ARIMA Model (Time-Series Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2641bdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ARIMA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling:Training ARIMA model with order=(1, 1, 1), seasonal=(1, 1, 1, 7)\n",
      "INFO:modeling:ARIMA AIC: 6056.26\n",
      "INFO:modeling:ARIMA AIC: 6056.26\n",
      "INFO:modeling:Model saved to ../02_Model_Development/Trained_Models/arima_model.pkl\n",
      "INFO:modeling:Model saved to ../02_Model_Development/Trained_Models/arima_model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA AIC: 6056.26\n",
      "‚úÖ ARIMA training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train ARIMA as baseline\n",
    "print(\"Training ARIMA...\")\n",
    "arima_model, arima_info = train_arima_model(\n",
    "    y_train,\n",
    "    order=(1, 1, 1),\n",
    "    seasonal_order=(1, 1, 1, 7),  # Weekly seasonality\n",
    "    save_path=str(MODEL_PATH / 'arima_model.pkl')\n",
    ")\n",
    "\n",
    "print(f\"ARIMA AIC: {arima_info['aic']:.2f}\")\n",
    "print(\"‚úÖ ARIMA training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d44f1b",
   "metadata": {},
   "source": [
    "## 6. Train LSTM Model (Optional - Requires TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ebc89ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM...\n",
      "‚ö†Ô∏è LSTM training skipped: name 'train_lstm_model' is not defined\n",
      "Install TensorFlow to enable LSTM training: pip install tensorflow\n"
     ]
    }
   ],
   "source": [
    "# LSTM requires sequential data\n",
    "# Create sequences for LSTM\n",
    "SEQUENCE_LENGTH = 7\n",
    "\n",
    "try:\n",
    "    # Prepare sequential data\n",
    "    X_seq_train, y_seq_train = create_sequences(\n",
    "        train_df[feature_cols + [target_col]].values,\n",
    "        sequence_length=SEQUENCE_LENGTH,\n",
    "        target_col_idx=-1\n",
    "    )\n",
    "    \n",
    "    X_seq_val, y_seq_val = create_sequences(\n",
    "        val_df[feature_cols + [target_col]].values,\n",
    "        sequence_length=SEQUENCE_LENGTH,\n",
    "        target_col_idx=-1\n",
    "    )\n",
    "    \n",
    "    # LSTM configuration\n",
    "    lstm_config = {\n",
    "        'units_layer1': 64,\n",
    "        'units_layer2': 32,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 0.001,\n",
    "        'epochs': 50,\n",
    "        'batch_size': 32\n",
    "    }\n",
    "    \n",
    "    print(\"Training LSTM...\")\n",
    "    lstm_model, lstm_history = train_lstm_model(\n",
    "        X_seq_train, y_seq_train,\n",
    "        X_seq_val, y_seq_val,\n",
    "        config=lstm_config,\n",
    "        save_path=str(MODEL_PATH / 'lstm_model')\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ LSTM training complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è LSTM training skipped: {e}\")\n",
    "    print(\"Install TensorFlow to enable LSTM training: pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b4343",
   "metadata": {},
   "source": [
    "## 7. Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f202341f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODEL TRAINING SUMMARY\n",
      "============================================================\n",
      "\n",
      "Models trained and saved to: ../02_Model_Development/Trained_Models\n",
      "\n",
      "Trained Models:\n",
      "  ‚úÖ XGBoost\n",
      "  ‚úÖ Random Forest\n",
      "  ‚úÖ ARIMA\n",
      "  ‚ö†Ô∏è LSTM (if TensorFlow available)\n",
      "\n",
      "============================================================\n",
      "MODEL TRAINING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Next Step: Run 06_Model_Evaluation.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Training summary\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nModels trained and saved to: {MODEL_PATH}\")\n",
    "print(\"\\nTrained Models:\")\n",
    "print(\"  ‚úÖ XGBoost\")\n",
    "print(\"  ‚úÖ Random Forest\")\n",
    "print(\"  ‚úÖ ARIMA\")\n",
    "print(\"  ‚ö†Ô∏è LSTM (if TensorFlow available)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNext Step: Run 06_Model_Evaluation.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
